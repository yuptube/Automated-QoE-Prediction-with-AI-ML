{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9adbf29e",
   "metadata": {},
   "source": [
    "## 1, Read csv files\n",
    "read csv files in DATA_PATH/.../... with the order of train, validation, and test dataset.\n",
    "\n",
    "##### output\n",
    "- - - - - - - -\n",
    "**list_data_raw**: list [pd.Dataframe, pd.Dataframe, ..., pd.Dataframe]\\\n",
    "    &nbsp;&nbsp;&nbsp; raw data (dataframe read from csv file) is stored in list format\\\n",
    "**y**: list [int, int, ..., int]\\\n",
    "    &nbsp;&nbsp;&nbsp; 0 if UBE, 1 if UGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dd43ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules to read csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import natsort\n",
    "\n",
    "# dataset path\n",
    "DATA_PATH   = \"./DataSet\"\n",
    "\n",
    "# function to list all files in the path\n",
    "paths = lambda x : [os.path.join(root, file) for root,dirs,files\n",
    "                          in os.walk(DATA_PATH + \"/\" + x) for file in natsort.natsorted(files)]\n",
    "\n",
    "# array to store all rawdata and y data\n",
    "list_data_raw, y     = [], []\n",
    "for _f_path in (paths(\"trainset\") + paths(\"validationset\") + paths(\"testset\")):\n",
    "    # gets raw data for current user csv and adds to list\n",
    "    list_data_raw.append(pd.read_csv(_f_path))\n",
    "    # gets y variable from file path (UBE:0, UGE:1)\n",
    "    y.append(1 if(\"UGE\" in _f_path) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9508be3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>specifictime</th>\n",
       "      <th>indicator1</th>\n",
       "      <th>indicator2</th>\n",
       "      <th>indicator3</th>\n",
       "      <th>indicator4</th>\n",
       "      <th>indicator5</th>\n",
       "      <th>indicator6</th>\n",
       "      <th>indicator7</th>\n",
       "      <th>indicator8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>18</td>\n",
       "      <td>2021-06-10 18:09:59</td>\n",
       "      <td>45.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>229.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>18</td>\n",
       "      <td>2021-06-10 18:09:59</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>18</td>\n",
       "      <td>2021-06-10 18:09:59</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>18</td>\n",
       "      <td>2021-06-10 18:09:59</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>25.50</td>\n",
       "      <td>300.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>18</td>\n",
       "      <td>2021-06-10 18:09:59</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9490</th>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-06-16 23:59:59</td>\n",
       "      <td>15.33</td>\n",
       "      <td>3.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>15.67</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-06-16 23:59:59</td>\n",
       "      <td>12.11</td>\n",
       "      <td>25.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>11.44</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-06-16 23:59:59</td>\n",
       "      <td>22.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>123.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-06-16 23:59:59</td>\n",
       "      <td>24.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>18.75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-06-16 23:59:59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9495 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             day  hour         specifictime  indicator1  indicator2  \\\n",
       "0     2021-06-10    18  2021-06-10 18:09:59       45.00       36.00   \n",
       "1     2021-06-10    18  2021-06-10 18:09:59       33.00        3.00   \n",
       "2     2021-06-10    18  2021-06-10 18:09:59       24.00        2.00   \n",
       "3     2021-06-10    18  2021-06-10 18:09:59        5.00        1.00   \n",
       "4     2021-06-10    18  2021-06-10 18:09:59        5.00        3.00   \n",
       "...          ...   ...                  ...         ...         ...   \n",
       "9490  2021-06-16    23  2021-06-16 23:59:59       15.33        3.67   \n",
       "9491  2021-06-16    23  2021-06-16 23:59:59       12.11       25.00   \n",
       "9492  2021-06-16    23  2021-06-16 23:59:59       22.00        5.00   \n",
       "9493  2021-06-16    23  2021-06-16 23:59:59       24.50        9.00   \n",
       "9494  2021-06-16    23  2021-06-16 23:59:59        0.00        0.00   \n",
       "\n",
       "      indicator3  indicator4  indicator5  indicator6  indicator7  indicator8  \n",
       "0           3.00       45.00       229.0        45.0      0.2000      0.0000  \n",
       "1           0.00       33.00         2.0        33.0      0.0000      0.0000  \n",
       "2           5.00       24.00         2.0        24.0      0.0000      0.0000  \n",
       "3           2.00       25.50       300.0        18.0      0.3404      0.1429  \n",
       "4           5.00        5.00         2.0         5.0      0.0000      0.2400  \n",
       "...          ...         ...         ...         ...         ...         ...  \n",
       "9490        6.67       15.67        10.0         7.0      0.0116      0.0093  \n",
       "9491       27.00       11.44        20.0        14.0      0.0055      0.0062  \n",
       "9492      123.00       22.00        24.0        23.0      0.0714      0.0000  \n",
       "9493        6.50       18.75         6.0        24.0      0.0000      0.0000  \n",
       "9494        0.00       15.50         0.0         0.0      0.0000      0.0000  \n",
       "\n",
       "[9495 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of input data (user1 of UBE)\n",
    "list_data_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc299e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "# labels\n",
    "print(' '.join(map(str, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceafd211",
   "metadata": {},
   "source": [
    "## 2, Feature extraction\n",
    "Extract features (number of dimension: 36) from each raw data.\\\n",
    "Pre-process and extract features based on insights from data networking protocols as well as an accurate histogram analysis, then this method is called \"Histogram-Based Feature Selection Method\".\n",
    "\n",
    "##### output\n",
    "- - - - - - - -\n",
    "**X**: pd.Dataframe\n",
    "\n",
    "| column        |type       | description               |\n",
    "| ------------- |:---------:| -------------------------:|\n",
    "| f_N (N=00~35) | float     | feature value             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "558678c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check chinese holiday \n",
    "import holidays\n",
    "\n",
    "china_holidays = holidays.China()\n",
    "list_chi_holiday = {}\n",
    "def check_holiday(date):\n",
    "    \"\"\"\n",
    "    Parameters (input data needed)\n",
    "    ---------------- \n",
    "    date: string\n",
    "        date with format \"YYYY-MM-DD\"\n",
    "\n",
    "    Returns\n",
    "    ---------------- \n",
    "    chinese_holiday.is_holiday(date): bool\n",
    "        True if input date is weekend\n",
    "        False if input date is midweek\n",
    "    \n",
    "    Notes\n",
    "    ----------------\n",
    "    Check the date input is holiday or not with chinese_holiday library.\n",
    "    This function saves the holidays to the dictionary (list_chi_holiday).\n",
    "    \"\"\"\n",
    "    if date not in list_chi_holiday.keys():\n",
    "        # this date is input at the first time\n",
    "        list_chi_holiday[date] = (date in china_holidays)\n",
    "    return list_chi_holiday[date]  # True(weekend), False(midweek)\n",
    "\n",
    "# definition of outlier ([outlier of indicator1, 2 , ... , 8])\n",
    "OUTLIER = [48.75, 101.5, 19.1, 50.5, 128, 47.5, 0.184629, 0.212225]\n",
    "\n",
    "# dataframe to store features of each data\n",
    "_columns_X = [\"f_\"+format(i,\"02\") for i in range(36)]\n",
    "X = pd.DataFrame(columns=_columns_X)\n",
    "\n",
    "# repititive loop of data for extracting features\n",
    "for _user_idx, data_raw in enumerate(list_data_raw):\n",
    "    \n",
    "    # data cleaning (number of dimension at output: 8)\n",
    "    data_clean  = data_raw[(data_raw[\"indicator1\"] > 0) & (data_raw[\"indicator2\"] > 0) &\n",
    "                           (data_raw[\"indicator4\"] > 0) & (data_raw[\"indicator5\"] > 0) &\n",
    "                           (data_raw[\"indicator6\"] > 0)] # remove data if either indicator 1/2/4/5/6 is zero\n",
    "    for _j in range(8):\n",
    "        # replace data exceding outlier for the outlier value\n",
    "        data_clean.loc[data_clean[\"indicator\" + str(_j+1)] > OUTLIER[_j], \"indicator\" + str(_j+1)] = OUTLIER[_j]\n",
    "    \n",
    "    # indicator grouping + averaging (number of dimension at output: 4)\n",
    "    data_group = data_clean[[\"day\", \"hour\"]]\n",
    "    data_group = data_group.assign(WAN_RTT  = data_clean[[\"indicator1\",\"indicator4\",\"indicator6\"]].mean(axis=1))\n",
    "    data_group = data_group.assign(LAN_RTT  = data_clean[[\"indicator2\",\"indicator5\"]].mean(axis=1))\n",
    "    data_group = data_group.assign(LAN_RES  = data_clean[\"indicator3\"])\n",
    "    data_group = data_group.assign(RET      = data_clean[[\"indicator7\",\"indicator8\"]].mean(axis=1))\n",
    "    \n",
    "    # definition of histogram-based indicator splitting\n",
    "    list_group_range = [] # definition of group range (R1 ~ R6)\n",
    "    list_group_range.append([\"LAN_RTT\",  ((data_group[\"LAN_RTT\"] > 0)    & (data_group[\"LAN_RTT\"] < 23))])\n",
    "    list_group_range.append([\"LAN_RTT\",  ((data_group[\"LAN_RTT\"] >= 23)  & (data_group[\"LAN_RTT\"] < 60))])\n",
    "    list_group_range.append([\"LAN_RES\",  ((data_group[\"LAN_RES\"] >= 0)   & (data_group[\"LAN_RES\"] < 19))])\n",
    "    list_group_range.append([\"WAN_RTT\",  ((data_group[\"WAN_RTT\"] > 0)    & (data_group[\"WAN_RTT\"] < 19))])\n",
    "    list_group_range.append([\"WAN_RTT\",  ((data_group[\"WAN_RTT\"] >= 19)  & (data_group[\"WAN_RTT\"] < 39))])\n",
    "    list_group_range.append([\"RET\",      ((data_group[\"RET\"]     >= 0)   & (data_group[\"RET\"]     < 0.18))])\n",
    "    # definition of temporal sample splitting\n",
    "    list_time_range = [] # definition of time range (T1 ~ T3)\n",
    "    list_time_range.append((data_group[\"hour\"] >= 0)     & (data_group[\"hour\"] < 7))\n",
    "    list_time_range.append((data_group[\"hour\"] >= 7)     & (data_group[\"hour\"] < 19))\n",
    "    list_time_range.append((data_group[\"hour\"] >= 19)    & (data_group[\"hour\"] < 24))\n",
    "    list_date_range = [] # definition of date range (D1 ~ D2)\n",
    "    list_date_range.append(data_clean[\"day\"].apply(lambda x: check_holiday(x)) == True)\n",
    "    list_date_range.append(data_clean[\"day\"].apply(lambda x: check_holiday(x)) == False)\n",
    "    \n",
    "    # histogram-based indicator splitting + temporal sample splitting (number of dimension at output: 36)\n",
    "    data_split = [] # temporal list to store features \n",
    "    for _date_range in list_date_range:\n",
    "        # sample splitting with date\n",
    "        for _time_range in list_time_range:\n",
    "            # sample splitting with time\n",
    "            for _group_range in list_group_range:\n",
    "                # histogram-based indicator splitting\n",
    "                \n",
    "                # Temporal mean value with normalization \n",
    "                _Norm_val = max(OUTLIER[6:8]) if _group_range[0] == \"RET\" else max(OUTLIER[0:6])\n",
    "                data_split.append(data_group[_group_range[0]][_group_range[1] & _time_range & _date_range].mean(axis=0) / _Norm_val\n",
    "                                  if (sum(_group_range[1] & _time_range & _date_range) > 0) else 0) \n",
    "    \n",
    "    # store features to X\n",
    "    X = pd.concat([X, pd.DataFrame([data_split], columns=_columns_X, index = [_user_idx+1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29386e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>f_09</th>\n",
       "      <th>...</th>\n",
       "      <th>f_26</th>\n",
       "      <th>f_27</th>\n",
       "      <th>f_28</th>\n",
       "      <th>f_29</th>\n",
       "      <th>f_30</th>\n",
       "      <th>f_31</th>\n",
       "      <th>f_32</th>\n",
       "      <th>f_33</th>\n",
       "      <th>f_34</th>\n",
       "      <th>f_35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084179</td>\n",
       "      <td>0.295864</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.082786</td>\n",
       "      <td>0.197693</td>\n",
       "      <td>0.071928</td>\n",
       "      <td>0.081747</td>\n",
       "      <td>0.331690</td>\n",
       "      <td>0.046552</td>\n",
       "      <td>0.087150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031234</td>\n",
       "      <td>0.083050</td>\n",
       "      <td>0.209908</td>\n",
       "      <td>0.102280</td>\n",
       "      <td>0.085309</td>\n",
       "      <td>0.325451</td>\n",
       "      <td>0.045230</td>\n",
       "      <td>0.091154</td>\n",
       "      <td>0.201221</td>\n",
       "      <td>0.108005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074255</td>\n",
       "      <td>0.285576</td>\n",
       "      <td>0.033693</td>\n",
       "      <td>0.077102</td>\n",
       "      <td>0.195812</td>\n",
       "      <td>0.065633</td>\n",
       "      <td>0.059618</td>\n",
       "      <td>0.281459</td>\n",
       "      <td>0.033251</td>\n",
       "      <td>0.080656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033441</td>\n",
       "      <td>0.079302</td>\n",
       "      <td>0.202995</td>\n",
       "      <td>0.054084</td>\n",
       "      <td>0.064287</td>\n",
       "      <td>0.283163</td>\n",
       "      <td>0.036156</td>\n",
       "      <td>0.092695</td>\n",
       "      <td>0.213434</td>\n",
       "      <td>0.061198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084629</td>\n",
       "      <td>0.303670</td>\n",
       "      <td>0.039559</td>\n",
       "      <td>0.084508</td>\n",
       "      <td>0.203009</td>\n",
       "      <td>0.025416</td>\n",
       "      <td>0.086439</td>\n",
       "      <td>0.298045</td>\n",
       "      <td>0.036924</td>\n",
       "      <td>0.078015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039487</td>\n",
       "      <td>0.081294</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.026739</td>\n",
       "      <td>0.085377</td>\n",
       "      <td>0.287670</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>0.083466</td>\n",
       "      <td>0.204464</td>\n",
       "      <td>0.024723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081984</td>\n",
       "      <td>0.306749</td>\n",
       "      <td>0.057647</td>\n",
       "      <td>0.079210</td>\n",
       "      <td>0.207192</td>\n",
       "      <td>0.103840</td>\n",
       "      <td>0.070810</td>\n",
       "      <td>0.327927</td>\n",
       "      <td>0.052282</td>\n",
       "      <td>0.082227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041342</td>\n",
       "      <td>0.080849</td>\n",
       "      <td>0.208708</td>\n",
       "      <td>0.093763</td>\n",
       "      <td>0.084030</td>\n",
       "      <td>0.320133</td>\n",
       "      <td>0.056008</td>\n",
       "      <td>0.081828</td>\n",
       "      <td>0.207380</td>\n",
       "      <td>0.103358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.066158</td>\n",
       "      <td>0.400596</td>\n",
       "      <td>0.050235</td>\n",
       "      <td>0.087643</td>\n",
       "      <td>0.218689</td>\n",
       "      <td>0.174248</td>\n",
       "      <td>0.066764</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.035425</td>\n",
       "      <td>0.084544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039950</td>\n",
       "      <td>0.085495</td>\n",
       "      <td>0.211541</td>\n",
       "      <td>0.087733</td>\n",
       "      <td>0.072108</td>\n",
       "      <td>0.356918</td>\n",
       "      <td>0.043809</td>\n",
       "      <td>0.087445</td>\n",
       "      <td>0.216348</td>\n",
       "      <td>0.112164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.065684</td>\n",
       "      <td>0.331129</td>\n",
       "      <td>0.032424</td>\n",
       "      <td>0.086648</td>\n",
       "      <td>0.201539</td>\n",
       "      <td>0.052793</td>\n",
       "      <td>0.140952</td>\n",
       "      <td>0.318939</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.086606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027422</td>\n",
       "      <td>0.067432</td>\n",
       "      <td>0.201625</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.149247</td>\n",
       "      <td>0.335381</td>\n",
       "      <td>0.036678</td>\n",
       "      <td>0.092964</td>\n",
       "      <td>0.200622</td>\n",
       "      <td>0.054021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.075787</td>\n",
       "      <td>0.282016</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>0.086277</td>\n",
       "      <td>0.191331</td>\n",
       "      <td>0.029836</td>\n",
       "      <td>0.067643</td>\n",
       "      <td>0.293731</td>\n",
       "      <td>0.025818</td>\n",
       "      <td>0.084087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032709</td>\n",
       "      <td>0.083412</td>\n",
       "      <td>0.193642</td>\n",
       "      <td>0.034385</td>\n",
       "      <td>0.068157</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.085791</td>\n",
       "      <td>0.195477</td>\n",
       "      <td>0.027344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.060370</td>\n",
       "      <td>0.357822</td>\n",
       "      <td>0.045292</td>\n",
       "      <td>0.074669</td>\n",
       "      <td>0.195266</td>\n",
       "      <td>0.121844</td>\n",
       "      <td>0.055614</td>\n",
       "      <td>0.323520</td>\n",
       "      <td>0.042283</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>0.070512</td>\n",
       "      <td>0.202101</td>\n",
       "      <td>0.076955</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>0.318106</td>\n",
       "      <td>0.040893</td>\n",
       "      <td>0.072987</td>\n",
       "      <td>0.197758</td>\n",
       "      <td>0.048949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.131995</td>\n",
       "      <td>0.274901</td>\n",
       "      <td>0.023212</td>\n",
       "      <td>0.061377</td>\n",
       "      <td>0.210305</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.140863</td>\n",
       "      <td>0.275197</td>\n",
       "      <td>0.017078</td>\n",
       "      <td>0.057989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>0.056173</td>\n",
       "      <td>0.212366</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>0.139036</td>\n",
       "      <td>0.275904</td>\n",
       "      <td>0.016876</td>\n",
       "      <td>0.059011</td>\n",
       "      <td>0.216358</td>\n",
       "      <td>0.017060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.089489</td>\n",
       "      <td>0.341245</td>\n",
       "      <td>0.049121</td>\n",
       "      <td>0.090358</td>\n",
       "      <td>0.208713</td>\n",
       "      <td>0.122932</td>\n",
       "      <td>0.078975</td>\n",
       "      <td>0.323108</td>\n",
       "      <td>0.039456</td>\n",
       "      <td>0.082174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046502</td>\n",
       "      <td>0.082724</td>\n",
       "      <td>0.212124</td>\n",
       "      <td>0.096615</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.359567</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.210199</td>\n",
       "      <td>0.072328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
       "1    0.084179  0.295864  0.042644  0.082786  0.197693  0.071928  0.081747   \n",
       "2    0.074255  0.285576  0.033693  0.077102  0.195812  0.065633  0.059618   \n",
       "3    0.084629  0.303670  0.039559  0.084508  0.203009  0.025416  0.086439   \n",
       "4    0.081984  0.306749  0.057647  0.079210  0.207192  0.103840  0.070810   \n",
       "5    0.066158  0.400596  0.050235  0.087643  0.218689  0.174248  0.066764   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "496  0.065684  0.331129  0.032424  0.086648  0.201539  0.052793  0.140952   \n",
       "497  0.075787  0.282016  0.027849  0.086277  0.191331  0.029836  0.067643   \n",
       "498  0.060370  0.357822  0.045292  0.074669  0.195266  0.121844  0.055614   \n",
       "499  0.131995  0.274901  0.023212  0.061377  0.210305  0.007975  0.140863   \n",
       "500  0.089489  0.341245  0.049121  0.090358  0.208713  0.122932  0.078975   \n",
       "\n",
       "         f_07      f_08      f_09  ...      f_26      f_27      f_28  \\\n",
       "1    0.331690  0.046552  0.087150  ...  0.031234  0.083050  0.209908   \n",
       "2    0.281459  0.033251  0.080656  ...  0.033441  0.079302  0.202995   \n",
       "3    0.298045  0.036924  0.078015  ...  0.039487  0.081294  0.203608   \n",
       "4    0.327927  0.052282  0.082227  ...  0.041342  0.080849  0.208708   \n",
       "5    0.331570  0.035425  0.084544  ...  0.039950  0.085495  0.211541   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "496  0.318939  0.033494  0.086606  ...  0.027422  0.067432  0.201625   \n",
       "497  0.293731  0.025818  0.084087  ...  0.032709  0.083412  0.193642   \n",
       "498  0.323520  0.042283  0.071397  ...  0.041688  0.070512  0.202101   \n",
       "499  0.275197  0.017078  0.057989  ...  0.018418  0.056173  0.212366   \n",
       "500  0.323108  0.039456  0.082174  ...  0.046502  0.082724  0.212124   \n",
       "\n",
       "         f_29      f_30      f_31      f_32      f_33      f_34      f_35  \n",
       "1    0.102280  0.085309  0.325451  0.045230  0.091154  0.201221  0.108005  \n",
       "2    0.054084  0.064287  0.283163  0.036156  0.092695  0.213434  0.061198  \n",
       "3    0.026739  0.085377  0.287670  0.035250  0.083466  0.204464  0.024723  \n",
       "4    0.093763  0.084030  0.320133  0.056008  0.081828  0.207380  0.103358  \n",
       "5    0.087733  0.072108  0.356918  0.043809  0.087445  0.216348  0.112164  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "496  0.080420  0.149247  0.335381  0.036678  0.092964  0.200622  0.054021  \n",
       "497  0.034385  0.068157  0.282500  0.027108  0.085791  0.195477  0.027344  \n",
       "498  0.076955  0.054393  0.318106  0.040893  0.072987  0.197758  0.048949  \n",
       "499  0.023791  0.139036  0.275904  0.016876  0.059011  0.216358  0.017060  \n",
       "500  0.096615  0.070200  0.359567  0.046874  0.077824  0.210199  0.072328  \n",
       "\n",
       "[500 rows x 36 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features table (dimension: 36)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f2000",
   "metadata": {},
   "source": [
    "## 3, Classifier model training\n",
    "Random Forest classifier learning with train dataset.\\\n",
    "Input data and labals are transformed into numpy format for applying grouped permutation importance study later.\n",
    "\n",
    "##### output\n",
    "- - - - - - - -\n",
    "**clf**: RandomForestClassifier\\\n",
    "    &nbsp;&nbsp;&nbsp; trained classifier model\\\n",
    "**X_train, X_val, X_test**: np.array([300, 36]), np.array([100, 36]), np.array([100, 36])\\\n",
    "    &nbsp;&nbsp;&nbsp; features table of train, validation, and test data set with numpy format\\\n",
    "**y_train, y_val, y_test**: np.array([300]), np.array([100]), np.array([100])\\\n",
    "    &nbsp;&nbsp;&nbsp; labels of train, validation, and test data set with numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ea6d1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=5,\n",
       "                       random_state=71666)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=5,\n",
       "                       random_state=71666)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features='log2', n_estimators=5,\n",
       "                       random_state=71666)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required modules to apply Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# devide features and label into train, validationset, and test set\n",
    "# transform those into numpy format for applying grouped permutation importance study later\n",
    "X_train, y_train    = X.iloc[:300].to_numpy(),     np.array(y[:300])\n",
    "X_val,   y_val      = X.iloc[300:400].to_numpy(),  np.array(y[300:400])\n",
    "X_test,  y_test     = X.iloc[400:500].to_numpy(),  np.array(y[400:500])\n",
    "\n",
    "# Random Forest model training\n",
    "clf = RandomForestClassifier(max_depth=10, n_estimators=5, max_features='log2', random_state=71666)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3460f",
   "metadata": {},
   "source": [
    "## 4, Classifier model save & load (if needed)\n",
    "Save & load the classifier model. This section is commented out by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d28ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import required modules to save & load the model\n",
    "# import pickle\n",
    "\n",
    "# # save model\n",
    "# _model = open('model.pkl', 'wb')\n",
    "# pickle.dump(clf, _model)\n",
    "# _model.close()\n",
    "\n",
    "# # load model\n",
    "# _model = open('model.pkl', 'rb')\n",
    "# clf = pickle.load(_model)\n",
    "# _model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516999e",
   "metadata": {},
   "source": [
    "## 5, Classifier model test\n",
    "Random Forest classifier predicting with test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0099740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# predict UBE or UGE of test set\n",
    "y_test_predict = clf.predict(X_test)\n",
    "print(y_test)\n",
    "print(y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11d877b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78        50\n",
      "           1       0.78      0.78      0.78        50\n",
      "\n",
      "    accuracy                           0.78       100\n",
      "   macro avg       0.78      0.78      0.78       100\n",
      "weighted avg       0.78      0.78      0.78       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import required modules to report the result\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# classification report (e.g. accuracy, F1 score)\n",
    "print(classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fb8d5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix report\n",
    "cm      = confusion_matrix(y_test, y_test_predict, labels=clf.classes_)\n",
    "disp    = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
